# -*- coding: utf-8 -*-
"""IITM_MBD_W5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q-tEyZg9AEk5uS2B5MqHQ2JsHuUjQV02
"""

import pandas as pd
from math import floor as floor
from datetime import datetime as dt
from datetime import timedelta as td

from google.colab import files
import io

uploaded = files.upload()
file_name = next(iter(uploaded.keys()))
xls = pd.ExcelFile(io.BytesIO(uploaded[file_name]))
WRITE_PATH = f"answers_{file_name.split('.')[0]}.csv"

def cleanup_function(x):
    if isinstance(x, str):
        return x.strip()
    else:
        return x

sku = pd.read_excel(xls, 'SKU MASTER').applymap(cleanup_function)
sales = pd.read_excel(xls, 'Sales').applymap(cleanup_function)
op_stock = pd.read_excel(xls, 'Opening Stock').applymap(cleanup_function)
stock_trans = pd.read_excel(xls, 'STOCK TRANSFER', header=None).applymap(cleanup_function)

# Init answers
ans = dict.fromkeys(["Q"+str(i) for i in range(1,6)], 0)

# Helper Function
def print_info(x):
    print(x.shape)
    print(x.columns)
    return x.head()

print_info(sku)

print_info(sales)

print_info(op_stock)

# Read without whole excel sheet
stock_trans = pd.read_excel(xls, "STOCK TRANSFER", header=None).applymap(cleanup_function)
# Replace NA values with last valid observation
stock_trans.iloc[0, :].ffill(inplace=True)

# Extract city names
city_names = stock_trans.iloc[0, 1:].unique()

# Transpose, correct column names, drop first row (cities), group by city.
stock_trans = stock_trans.transpose()
stock_trans.columns = stock_trans.iloc[0, :].to_list()
stock_trans.drop(0, inplace=True)
stock_trans = stock_trans.groupby(["City"]).agg(list)


def regenerate_columns(x, city):
    x = pd.DataFrame(x.loc[city].to_dict()).T
    x = x.set_axis(x.iloc[0], axis=1).iloc[1:]

    return x

stock_trans_lookup = {
    city: regenerate_columns(stock_trans, city) for city in city_names
}

stock_trans_lookup["Pune"].head()

# 1. Over the 30 days of observed sales, what is the total sale value of SKU B003 ?(INTEGER)

price = sku[sku.SKU == 'B003'].Price.sum()
sold = sales[(sales["SKU"] == "B003")].Sales.sum()
ans["Q1"] = sold*price

ans["Q1"]

# 2. How much percentage of total sale quantity (Volume) did Household category achieve in the first week?
# (Jan 1 to Jan 7, both days included) (FLOAT - 3 decimal places)

household_skus = sku[sku.Category == "Household"].SKU.to_list()
sales_w1 = sales[(sales["Date"] >= dt(2023, 1, 1)) & (sales["Date"] <= dt(2023, 1, 7))]
ans["Q2"] = round(
    sales_w1[(sales_w1.SKU.isin(household_skus))].Sales.sum() / sales_w1.Sales.sum(), 3
)

ans["Q2"]

# 3. What is the maximum sale value by a single SKU in a day across all days? (INTEGER)
# (Sale Value = Sale Qty * Price per Qty)

joint = sales.merge(sku[['SKU', 'Price']], on="SKU")
joint['sale_value'] = joint['Sales'] * joint['Price']

ans["Q3"] = joint.sale_value.max()

ans["Q3"]

# 4. What is the least revenue generating category across all days? (STRING)

joint = sales.merge(sku[["SKU", "Category", "Price"]], on="SKU")
joint["sale_value"] = joint["Sales"] * joint["Price"]

ans["Q4"] = joint.groupby(["Category"]).agg({"sale_value": "sum"}).idxmin().iloc[0]
ans["Q4"]

# 5. What is the percentage of sale value in Mumbai across all categories and days? (FLOAT - 3 decimal places)

joint = sales.merge(sku[['SKU', 'Price']], on='SKU')
joint['sale_value'] = joint['Sales'] * joint['Price']

ans["Q5"] = round(joint[joint["City"] == "Mumbai"].sale_value.sum() / joint.sale_value.sum(), 3)
ans["Q5"] # Incorrect

output = "\n".join([",".join(str(item) for item in items) for items in ans.items()])

with open(WRITE_PATH, "w+") as f:
    f.write(output)

files.download(WRITE_PATH)